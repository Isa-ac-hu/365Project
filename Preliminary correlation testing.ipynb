{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681c38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\isaac\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\isaac\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\isaac\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\isaac\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\isaac\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "688c345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Gender Item Purchased  Purchase Amount (USD)       Location  \\\n",
      "0      55    Male         Blouse                     53       Kentucky   \n",
      "1      19    Male        Sweater                     64          Maine   \n",
      "2      50    Male          Jeans                     73  Massachusetts   \n",
      "3      21    Male        Sandals                     90   Rhode Island   \n",
      "4      45    Male         Blouse                     49         Oregon   \n",
      "...   ...     ...            ...                    ...            ...   \n",
      "3895   40  Female         Hoodie                     28       Virginia   \n",
      "3896   52  Female       Backpack                     49           Iowa   \n",
      "3897   46  Female           Belt                     33     New Jersey   \n",
      "3898   44  Female          Shoes                     77      Minnesota   \n",
      "3899   52  Female        Handbag                     81     California   \n",
      "\n",
      "          Color  Season  Review Rating  brightness  \n",
      "0          Gray  Winter            3.1           0  \n",
      "1        Maroon  Winter            3.1           0  \n",
      "2        Maroon  Spring            3.1           0  \n",
      "3        Maroon  Spring            3.5           0  \n",
      "4     Turquoise  Spring            2.7           1  \n",
      "...         ...     ...            ...         ...  \n",
      "3895  Turquoise  Summer            4.2           1  \n",
      "3896      White  Spring            4.5           1  \n",
      "3897      Green  Spring            2.9           1  \n",
      "3898      Brown  Summer            3.8           0  \n",
      "3899      Beige  Spring            3.1           0  \n",
      "\n",
      "[3900 rows x 9 columns]\n",
      "Accuracy of decision tree: 0.7217948717948718\n",
      "Accuracy of logistic regression: \n",
      "Train Score: 0.7240384615384615\n",
      "Test Score: 0.7217948717948718\n",
      "Accuracy of K neighbors: \n",
      "Train Score: 0.6705128205128206\n",
      "Test Score: 0.6538461538461539\n",
      "Accuracy of support vector classifier: \n",
      "Train Score: 0.7240384615384615\n",
      "Test Score: 0.7217948717948718\n",
      "Accuracy of decision tree: \n",
      "Train Score: 0.7240384615384615\n",
      "Test Score: 0.7217948717948718\n",
      "Accuracy of random forest: \n",
      "Train Score: 0.7240384615384615\n",
      "Test Score: 0.7217948717948718\n",
      "Accuracy of native bayes: \n",
      "Train Score: 0.7240384615384615\n",
      "Test Score: 0.7217948717948718\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Replace 'your_file_path.xlsx' with the actual path to your Excel file\n",
    "excel_file_path = 'shopping_trends.csv'\n",
    "\n",
    "# Read the Excel file into a Pandas DataFrame\n",
    "df = pd.read_csv(excel_file_path)\n",
    "\n",
    "# Now, you can work with the DataFrame 'df'\n",
    "# For example, you can print the first few rows\n",
    "# Assuming your DataFrame is named 'df'\n",
    "columns_to_keep = [1, 2, 3, 5, 6, 8, 9, 10]\n",
    "df = df.iloc[:, columns_to_keep]\n",
    "\n",
    "#print(df.head())\n",
    "\n",
    "pima = df\n",
    "\n",
    "# Define a function to categorize colors into bright or dim\n",
    "def categorize_brightness(color):\n",
    "    # You can adjust the criteria based on your preference\n",
    "    old_people_colors = ['black', 'Gray', 'Charcoal', 'Silver', 'Lavender', 'Maroon', 'Beige', 'Brown']\n",
    "    return 0 if color in old_people_colors else 1\n",
    "\n",
    "\n",
    "\n",
    "# Create a new column 'brightness' based on bright or dim categories\n",
    "pima['brightness'] = pima['Color'].apply(categorize_brightness)\n",
    "\n",
    "X = pima.iloc[:, [0]]  # Features\n",
    "y = pima.iloc[:, 8]  # Target variable\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "print(pima)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "\n",
    "\n",
    "#To store results of models, we create two dictionaries\n",
    "result_dict_train = {}\n",
    "result_dict_test = {}\n",
    "\n",
    "\n",
    "print(\"Accuracy of decision tree:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "reg = LogisticRegression(random_state = 42)\n",
    "accuracies = cross_val_score(reg, X_train, y_train, cv=5)\n",
    "reg.fit(X_train,y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of logistic regression: \")\n",
    "\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",reg.score(X_test,y_test))\n",
    "\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "accuracies = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    " \n",
    "#Obtain accuracy\n",
    "print(\"Accuracy of K neighbors: \")\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",knn.score(X_test,y_test))\n",
    "\n",
    "svc = SVC(random_state = 42)\n",
    "accuracies = cross_val_score(svc, X_train, y_train, cv=5)\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    " \n",
    "#Obtain accuracy\n",
    "print(\"Accuracy of support vector classifier: \")\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",svc.score(X_test,y_test))\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "accuracies = cross_val_score(dtc, X_train, y_train, cv=5)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    " \n",
    "#Obtain accuracy\n",
    "print(\"Accuracy of decision tree: \")\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",dtc.score(X_test,y_test))\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 42)\n",
    "accuracies = cross_val_score(rfc, X_train, y_train, cv=5)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    " \n",
    "    \n",
    "print(\"Accuracy of random forest: \")    \n",
    "#Obtain accuracy\n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",rfc.score(X_test,y_test))\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "accuracies = cross_val_score(gnb, X_train, y_train, cv=5)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    " \n",
    "#Obtain accuracy\n",
    "print(\"Accuracy of native bayes: \") \n",
    "print(\"Train Score:\",np.mean(accuracies))\n",
    "print(\"Test Score:\",gnb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1393b1d5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
